# GoodBench
collection of some good benchmarks

Vision Language:
1. Saliency-Bench: A Comprehensive Benchmark for Evaluating Visual Explanations

åŸƒé»˜é‡Œå¤§å­¦å›¢é˜Ÿæ¨å‡ºé¦–ä¸ªè¦†ç›–8ä¸ªçœŸå®ä»»åŠ¡ã€å¸¦æœ‰äººç±»è§£é‡ŠçœŸå€¼çš„è§†è§‰è§£é‡ŠåŸºå‡†Saliency-Bench

è®ºæ–‡é“¾æ¥:Â https://arxiv.org/abs/2310.08537
é¡¹ç›®ä¸»é¡µ:Â 
https://github.com/yifeizhangcs/XAIdataset.github.io
æ•°æ®ä¸»é¡µï¼šhttps://xaidataset.github.io/dataset/
ç‰¹ç‚¹ï¼š
* å…¨é¢çš„æ•°æ®é›†é›†åˆï¼šç²¾å¿ƒæ„å»ºå¹¶æ ‡æ³¨äº†8ä¸ªæ•°æ®é›†ï¼Œè¦†ç›–äº†ä»æ€§åˆ«åˆ†ç±»ã€ç¯å¢ƒè¯†åˆ«åˆ°ç™Œç—‡è¯Šæ–­å’Œè¡Œä¸ºåˆ†ç±»ç­‰å¤šç§ä»»åŠ¡ï¼Œå¹¶ä¸”åŒ…å«äº†äºŒåˆ†ç±»å’Œå¤šåˆ†ç±»é—®é¢˜ã€‚
* æ ‡å‡†åŒ–çš„è¯„ä¼°æµç¨‹ï¼šå¼€å‘äº†ä¸€å¥—ç»Ÿä¸€çš„è¯„ä¼°æµæ°´çº¿ï¼Œèƒ½å¤Ÿå¯¹ä¸åŒæ˜¾è‘—æ€§æ–¹æ³•ç”Ÿæˆçš„è§†è§‰è§£é‡Šè¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ï¼Œå¹¶ä½¿ç”¨ç»Ÿä¸€çš„æŒ‡æ ‡è¿›è¡Œè¡¡é‡ï¼Œç¡®ä¿äº†å®éªŒçš„å¯å¤ç°æ€§ã€‚
* å¹¿æ³›çš„åŸºå‡†æµ‹è¯•å’Œåˆ†æï¼šå¯¹6ç§ä¸»æµçš„æ˜¾è‘—æ€§æ–¹æ³•ï¼ˆå¦‚GradCAM, RISEç­‰ï¼‰åœ¨ä¸åŒæ¨¡å‹æ¶æ„ï¼ˆResNet-18, VGG-19, ViTï¼‰ä¸Šè¿›è¡Œäº†å¤§è§„æ¨¡çš„åŸºå‡†æµ‹è¯•ï¼Œå¹¶æä¾›äº†æ·±å…¥çš„æ€§èƒ½åˆ†æã€‚
* ç”¨æˆ·å‹å¥½çš„è¯„ä¼°å·¥å…·åŒ…ï¼šæä¾›äº†ä¸€ä¸ªæ˜“äºä½¿ç”¨çš„Pythonå·¥å…·åŒ…ï¼Œå°è£…äº†æ•°æ®åŠ è½½ã€æ¨¡å‹è¯„ä¼°ç­‰åŠŸèƒ½ï¼Œæå¤§åœ°ç®€åŒ–äº†ç ”ç©¶äººå‘˜çš„è¯„ä¼°è¿‡ç¨‹ã€‚

2. è®ºæ–‡æ ‡é¢˜ï¼šOCRBench v2: An Improved Benchmark for Evaluating Large Multimodal Models on Visual Text Localization and Reasoning

è®ºæ–‡åœ°å€ï¼šhttps://arxiv.org/pdf/2501.00321

æ¦œå•åœ°å€ï¼šhttps://99franklin.github.io/ocrbench_v2/

ä»£ç åœ°å€ï¼šhttps://github.com/Yuliang-Liu/MultimodalOCR

å…¬å¼€æ•°æ®é“¾æ¥ï¼šhttps://huggingface.co/datasets/ling99/OCRBench_v2

3. Lmgame Bench
UCSDç­‰æ¨å‡ºLmgame Benchæ ‡å‡†æ¡†æ¶ï¼Œç»“åˆå¤šæ¬¾ç»å…¸æ¸¸æˆï¼Œåˆ†æ¨¡å—æµ‹è¯„æ¨¡å‹çš„æ„ŸçŸ¥ã€è®°å¿†ä¸æ¨ç†è¡¨ç°ã€‚
ç»“æœæ˜¾ç¤ºï¼Œä¸åŒæ¨¡å‹åœ¨å„æ¸¸æˆä¸­è¡¨ç°è¿¥å¼‚ï¼Œå‡¸æ˜¾æ¸¸æˆä½œä¸ºAIè¯„ä¼°å·¥å…·çš„ç‹¬ç‰¹ä»·å€¼ã€‚
https://lmgame.org/#/blog/pokemon_red
https://x.com/haoailab/status/1939777711502946544

4. ocr-reasoning
è®ºæ–‡æ ‡é¢˜ï¼šOCR-Reasoning Benchmark: Unveiling the True Capabilities of MLLMs in Complex Text-Rich Image Reasoning
è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/pdf/2505.17163
ä»£ç é“¾æ¥ï¼šhttps://github.com/SCUT-DLVCLab/OCR-Reasoning
é¡¹ç›®ä¸»é¡µï¼šhttps://ocr-reasoning.github.io/

5. VSI-Bench
test ability to think in space
Humans possess the visual-spatial intelligence to remember spaces from sequential visual observations. However, can Multimodal Large Language Models (MLLMs) trained on million-scale video datasets also ``think in space'' from videos? We present a novel video-based visual-spatial intelligence benchmark (VSI-Bench) of over 5,000 question-answer pairs, and find that MLLMs exhibit competitive - though subhuman - visual-spatial intelligence. We probe models to express how they think in space both linguistically and visually and find that while spatial reasoning capabilities remain the primary bottleneck for MLLMs to reach higher benchmark performance, local world models and spatial awareness do emerge within these models. Notably, prevailing linguistic reasoning techniques (e.g., chain-of-thought, self-consistency, tree-of-thoughts) fail to improve performance, whereas explicitly generating cognitive maps during question-answering enhances MLLMs' spatial distance ability.

https://huggingface.co/datasets/nyu-visionx/VSI-Bench

https://arxiv.org/abs/2412.14171

6. WildDoc
å­—èŠ‚è·³åŠ¨æå‡ºçš„ï¼Œocr bench
https://github.com/bytedance/WildDoc

https://huggingface.co/datasets/ByteDance/WildDoc

7.  ViewSpatial-Bench
è®ºæ–‡é“¾æ¥ï¼š
https://arxiv.org/abs/2505.21500
é¡¹ç›®ä¸»é¡µï¼š
https://zju-real.github.io/ViewSpatial-Page
GitHubä»“åº“ï¼š
https://github.com/ZJU-REAL/ViewSpatial-Bench


8. MME-reasoning
å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (MLLMs) çš„å…³é”®èƒ½åŠ›ã€‚éšç€DeepSeek-R1ç­‰å…·å¤‡å¼ºå¤§æ¨ç†èƒ½åŠ›çš„LLMçš„å‡ºç°ï¼Œç ”ç©¶äººå‘˜å¼€å§‹æ¢ç´¢å¦‚ä½•å°†æ¨ç†èƒ½åŠ›å¼•å…¥å¤šæ¨¡æ€å¤§æ¨¡å‹(MLLMs)ã€‚

ç„¶è€Œï¼Œç°æœ‰çš„benchmarkå¤§å¤šç¼ºä¹å¯¹é€»è¾‘æ¨ç†ç±»å‹çš„æ˜ç¡®åˆ†ç±»ï¼Œä»¥åŠå¯¹é€»è¾‘æ¨ç†çš„ç†è§£ä¸å¤Ÿæ¸…æ™°ï¼Œå¸¸å°†æ„ŸçŸ¥èƒ½åŠ›æˆ–çŸ¥è¯†å¹¿åº¦ä¸æ¨ç†èƒ½åŠ›æ··æ·†ã€‚

åœ¨æ­¤èƒŒæ™¯ä¸‹ï¼Œå¤æ—¦å¤§å­¦åŠé¦™æ¸¯ä¸­æ–‡å¤§å­¦MMLabè”åˆä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤ç­‰å¤šå®¶å•ä½ï¼Œæå‡ºäº†MME-Reasoningï¼Œæ—¨åœ¨å…¨é¢çš„è¯„ä¼°å¤šæ¨¡æ€å¤§æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/pdf/2505.21327
ä»£ç é“¾æ¥ï¼šhttps://github.com/Alpha-Innovator/MME-Reasoning
æ•°æ®é›†é“¾æ¥ï¼šhttps://huggingface.co/datasets/U4R/MME-Reasoning




è¡Œä¸šæµ‹è¯•é›†ï¼š
1. DrafterBench
é¦–ä¸ªå·¥ç¨‹è‡ªåŠ¨åŒ–ä»»åŠ¡è¯„ä¼°åŸºå‡†DrafterBenchï¼Œå¯ç”¨äºæµ‹è¯•å¤§è¯­è¨€æ¨¡å‹åœ¨åœŸæœ¨å·¥ç¨‹å›¾çº¸ä¿®æ”¹ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚é€šè¿‡æ¨¡æ‹ŸçœŸå®å·¥ç¨‹å‘½ä»¤ï¼Œå…¨é¢è€ƒå¯Ÿæ¨¡å‹çš„ç»“æ„åŒ–æ•°æ®ç†è§£ã€å·¥å…·è°ƒç”¨ã€æŒ‡ä»¤è·Ÿéšå’Œæ‰¹åˆ¤æ€§æ¨ç†èƒ½åŠ›ï¼Œç ”ç©¶ç»“æœå‘ç°å½“å‰ä¸»æµå¤§æ¨¡å‹è™½æœ‰ä¸€å®šèƒ½åŠ›ï¼Œä½†æ•´ä½“æ°´å¹³ä»ä¸è¶³ä»¥æ»¡è¶³å·¥ç¨‹ä¸€çº¿éœ€æ±‚ã€‚

è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2507.11527
ä»£ç é“¾æ¥ï¼šhttps://github.com/Eason-Li-AIS/DrafterBench
æ•°æ®é“¾æ¥ï¼šhttps://huggingface.co/datasets/Eason666/DrafterBench


2. ChemTable

https://huggingface.co/datasets/ustc-zyt/ChemTable

https://github.com/lqzxt/ChemTable
1ï¸âƒ£Â é¦–ä¸ªåŒ–å­¦è¡¨æ ¼ç»¼åˆåŸºå‡†ChemTableï¼šæ„å»ºå¹¶å‘å¸ƒäº†ä¸€ä¸ªåŒ…å«è¶…è¿‡1300ä¸ªçœŸå®åŒ–å­¦è¡¨æ ¼çš„å¤§è§„æ¨¡åŸºå‡†ï¼Œä¸“é—¨ç”¨äºè¯„ä¼°MLLMåœ¨åŒ–å­¦è¡¨æ ¼è¯†åˆ«å’Œç†è§£æ–¹é¢çš„ç»¼åˆèƒ½åŠ›ã€‚

2ï¸âƒ£Â æ·±åº¦å¤šæ¨¡æ€ä¸é¢†åŸŸç‰¹å®šè®¾è®¡ï¼šChemTableçš„æ ‡æ³¨æå…¶è¯¦å°½ï¼ŒåŒ…å«äº†å•å…ƒæ ¼å¤šè¾¹å½¢ã€é€»è¾‘å¸ƒå±€ã€é¢†åŸŸç‰¹å®šæ ‡ç­¾ï¼ˆè¯•å‰‚ã€å‚¬åŒ–å‰‚ã€äº§ç‡ç­‰ï¼‰å’ŒåµŒå…¥çš„åˆ†å­å›¾å½¢ï¼Œå¹¶è®¾è®¡äº†ä»åŸºç¡€æè¿°åˆ°å¤æ‚æ¨ç†çš„è¶…è¿‡9000ä¸ªé—®ç­”å®ä¾‹ã€‚
3ï¸âƒ£Â ç³»ç»Ÿæ€§æ­ç¤ºå½“å‰MLLMçš„å±€é™æ€§ï¼šé€šè¿‡å¯¹ä¸€ç³»åˆ—ä¸»æµå¼€æºå’Œé—­æºMLLMçš„è¯„ä¼°ï¼Œè®ºæ–‡æ¸…æ™°åœ°æ­ç¤ºäº†å®ƒä»¬åœ¨å¤„ç†åŒ–å­¦è¡¨æ ¼æ—¶çš„æ˜¾è‘—æ€§èƒ½å·®è·â€”â€”ä¸ä»…ä¸äººç±»ä¸“å®¶ç›¸æ¯”å­˜åœ¨å·¨å¤§é¸¿æ²Ÿï¼Œå¼€æºä¸é—­æºæ¨¡å‹ä¹‹é—´ä¹Ÿå·®å¼‚æ˜æ˜¾ã€‚


3. CovDocker: Benchmarking Covalent Drug Design with Tasks, Datasets, and Solutions

ğŸ“è®ºæ–‡é“¾æ¥ï¼šarxiv.org/pdf/2506.21085v1
ğŸ§ é¡¹ç›®åœ°å€ï¼šgithub.com/PoloWitty/CovDocker
ğŸ“¦æ•°æ®é›†ï¼šdoi.org/10.5281/zenodo.12805810

4.  MATP-BENCH
ä¸€ä¸ªæ–°æ¨å‡ºçš„å¤šæ¨¡æ€è‡ªåŠ¨å®šç†è¯æ˜åŸºå‡†ï¼Œæ—¨åœ¨è¯„ä¼°å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨å¤„ç†åŒ…å«å›¾åƒå’Œæ–‡æœ¬çš„å‡ ä½•å®šç†è¯æ˜ä¸­çš„èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ï¼Œå°½ç®¡æ¨¡å‹åœ¨å°†å›¾æ–‡ä¿¡æ¯è½¬åŒ–ä¸ºå½¢å¼åŒ–å®šç†æ–¹é¢æœ‰ä¸€å®šèƒ½åŠ›ï¼Œä½†åœ¨æ„å»ºå®Œæ•´è¯æ˜æ—¶é¢ä¸´é‡å¤§æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯å¤æ‚é€»è¾‘æ¨ç†å’Œè¾…åŠ©çº¿æ„é€ æ–¹é¢ã€‚

è®ºæ–‡åœ°å€ï¼šhttps://arxiv.org/pdf/2506.06034

é¡¹ç›®ä¸»é¡µï¼šhttps://matpbench.github.io/

5. æ–°åŸºå‡†åä¸ºSeePhysï¼Œå¼ºè°ƒäº†å›¾å½¢æ„ŸçŸ¥å¯¹äºæ¨¡å‹è®¤è¯†å’Œç†è§£ç‰©ç†ä¸–ç•Œçš„é‡è¦æ€§ã€‚

å†…å®¹æ¶µç›–ç»å…¸ä¸ç°ä»£ç‰©ç†çš„å„ä¸ªçŸ¥è¯†ç­‰çº§å’Œé¢†åŸŸï¼ŒåŒ…æ‹¬ä»åˆä¸­åˆ°åšå£«èµ„æ ¼è€ƒè¯•çš„å…¨è°±ç³»å¤šæ¨¡æ€ç‰©ç†é—®é¢˜ã€‚

å‚èµ›é“¾æ¥ï¼šhttps://www.codabench.org/competitions/7925/
æŒ‘æˆ˜èµ›è¯¦ç»†ä¿¡æ¯ï¼šhttps://sites.google.com/view/ai4mathworkshopicml2025/challenge
ICML workshop ä¸»é¡µï¼šhttps://sites.google.com/view/ai4mathworkshopicml2025/home

è®ºæ–‡ï¼šhttps://arxiv.org/pdf/2505.19099
é¡¹ç›®ä¸»é¡µï¼šhttps://github.com/SeePhys/seephys-project

6. PhyXï¼ˆPhysical Reasoning Benchmarkï¼‰
ç‰©ç†åŸºå‡†ï¼Œå¤šæ¨¡æ€

ç ”ç©¶äººå‘˜æ„å»ºäº†PhyXï¼ˆPhysical Reasoning Benchmarkï¼‰ï¼Œé¦–ä¸ªä¸“é—¨é¢å‘å¤šæ¨¡æ€å¤§æ¨¡å‹ç‰©ç†æ¨ç†èƒ½åŠ›çš„å¤§è§„æ¨¡åŸºå‡†æµ‹è¯•ã€‚

PhyXåŒ…å«3000é“é¢˜ç›®ï¼Œæ¶µç›–6å¤§ç‰©ç†å­¦ç§‘ï¼ˆåŠ›å­¦ã€ç”µç£ã€çƒ­å­¦ã€å…‰å­¦ã€æ³¢åŠ¨ã€ç°ä»£ç‰©ç†ï¼‰ï¼Œ25ä¸ªç»†åˆ†å­ç±»ä¸6ç±»æ¨ç†æ–¹å¼ï¼ˆå¦‚ç©ºé—´ç†è§£ã€ç‰©ç†å»ºæ¨¡ã€å…¬å¼è”ç«‹ã€é¢„æµ‹æ€§æ¨ç†ç­‰ï¼‰ï¼Œæ¯é“é¢˜ç›®éƒ½ç»“åˆæ•™æçº§å›¾åƒä¸çœŸå®ç‰©ç†è®¾å®šï¼Œå¹¶ç”±STEMä¸“ä¸šç ”ç©¶ç”Ÿç²¾å¿ƒå®¡æ ¸ã€‚

Project Page: https://phyx-bench.github.io/

Arxiv: https://arxiv.org/abs/2505.15929

Github: https://github.com/NastyMarcus/PhyX

Huggingface Dataset: https://huggingface.co/datasets/Cloudriver/PhyX

7. VCBench

ä¸Šè¿°ç»“è®ºæ¥è‡ªè¾¾æ‘©é™¢æ¨å‡ºçš„æ–°åŸºå‡†VCBenchâ€”â€”è¿™æ˜¯ä¸€ä¸ªä¸“ä¸ºè¯„ä¼°å…·å¤‡æ˜¾å¼è§†è§‰ä¾èµ–æ€§çš„å¤šæ¨¡æ€æ•°å­¦æ¨ç†ä»»åŠ¡è€Œè®¾è®¡çš„ç»¼åˆåŸºå‡†ã€‚

è¯¥åŸºå‡†ä¸»è¦é¢å‘å°å­¦ 1-6 å¹´çº§çš„æ•°å­¦é—®é¢˜ï¼Œå³å¹¶ä¸æ¶‰åŠå¤æ‚çš„æ•°å­¦æˆ–å‡ ä½•æ¨ç†ï¼Œä½†é«˜åº¦ä¾èµ–äºæ˜¾å¼çš„è§†è§‰ä¾èµ–æ€§çš„é—®é¢˜ã€‚

è§£å†³è¿™ç§é—®é¢˜ï¼Œéœ€è¦æ¨¡å‹è¯†åˆ«å’Œæ•´åˆå›¾åƒä¸­çš„è§†è§‰ç‰¹å¾ï¼Œå¹¶ç†è§£ä¸åŒè§†è§‰å…ƒç´ ä¹‹é—´çš„å…³ç³»ã€‚

è®ºæ–‡é“¾æ¥ï¼šhttp://arxiv.org/abs/2504.18589
æ•°æ®ä»“åº“ï¼šhttps://huggingface.co/datasets/cloudcatcher2/VCBench
ä»£ç ï¼šhttps://github.com/alibaba-damo-academy/VCBench
ç½‘é¡µï¼šhttps://alibaba-damo-academy.github.io/VCBench/

8. ml space
è‹¹æœæ¨å‡ºå¤§æ¨¡å‹â€œç©ºé—´è®¤çŸ¥èƒ½åŠ›â€æµ‹è¯•åŸºå‡†ï¼šSPACEï¼Œåˆç»™ç«çƒ­çš„å¤§æ¨¡å‹å¸‚åœºæµ‡äº†ç›†å†·æ°´
paper: https://arxiv.org/pdf/2410.06468
https://github.com/apple/ml-space-benchmark

9. OmnixR: Evaluating Omni-modality Language Models on Reasoning across Modalities

10. LogicGameï¼Œæ—¨åœ¨å…¨é¢è¯„ä¼° LLM åœ¨è§„åˆ™ç†è§£ã€æ‰§è¡Œå’Œè§„åˆ’æ–¹é¢çš„èƒ½åŠ›ã€‚å…ˆçœ‹è¯„æµ‹ç»“æœï¼š

LogicGame: Benchmarking Rule-Based Reasoning Abilities of Large Language Models

è®ºæ–‡é“¾æ¥ï¼š
https://arxiv.org/abs/2408.15778

https://github.com/Hypatiaalegra/LogicGame-Data


Language:

1. å¤šä»»åŠ¡åŸºå‡†ï¼š
è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºRESTçš„æ–°åŸºå‡†æ¡†æ¶ï¼Œç”¨äºè¯„ä¼°å¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLRMsï¼‰åœ¨å¤šé—®é¢˜å‹åŠ›ä¸‹çš„é²æ£’æ€§ã€‚ä¸ä¼ ç»Ÿçš„å•é—®é¢˜è¯„ä¼°ä¸åŒï¼ŒRESTé€šè¿‡åœ¨å•ä¸ªæç¤ºä¸­å‘ˆç°å¤šä¸ªæ¨ç†é—®é¢˜æ¥æµ‹è¯•æ¨¡å‹ï¼Œæ›´å¥½åœ°æ¨¡æ‹Ÿäº†çœŸå®ä¸–ç•Œçš„å¤šä»»åŠ¡å¤„ç†éœ€æ±‚ã€‚
è®ºæ–‡æ ‡é¢˜ï¼šREST: Stress Testing Large Reasoning Models by Asking Multiple Problems at OnceÂ 
è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2507.10541

2. MMLU-CFæ˜¯ä¸€ä¸ªæ— æ±¡æŸ“çš„å¤šä»»åŠ¡è¯­è¨€ç†è§£åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨æ›´å…¬å¹³ã€å‡†ç¡®åœ°è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ã€‚é€šè¿‡å»æ±¡æŸ“è§„åˆ™å’Œé—­æºæµ‹è¯•é›†é˜²æ­¢æ•°æ®æ³„éœ²ï¼Œç¡®ä¿è¯„ä¼°ç»“æœå¯é ã€‚è¯¥åŸºå‡†åŒ…å«20,000é“é¢˜ç›®ï¼Œæ¶µç›–14ä¸ªå­¦ç§‘ï¼ŒéªŒè¯é›†å…¬å¼€é€æ˜ï¼Œæµ‹è¯•é›†é—­æºé˜²æ³„éœ²

è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/pdf/2412.15194
ä»£ç é“¾æ¥ï¼šhttps://github.com/microsoft/MMLU-CF
æ•°æ®è¿æ¥ï¼šhttps://huggingface.co/datasets/microsoft/MMLU-CF


3. èšç„¦å†å²ç ”ç©¶èƒ½åŠ›çš„AIè¯„æµ‹åŸºå‡†â€”â€”HistBench

è®ºæ–‡åœ°å€ï¼šhttp://arxiv.org/abs/2505.20246
ä»£ç é“¾æ¥: https://github.com/CharlesQ9/HistAgent


4.  Reasoning Bench(RBench)[1], 

ä¸€ä¸ªå¤šå­¦ç§‘ã€å¤šè¯­è¨€çš„é«˜è´¨é‡å¤æ‚æ¨ç†è¯„ä¼°åŸºå‡†å’Œæ•°æ®é›†ï¼Œå…¼é¡¾è¯­è¨€æ¨¡å‹ä¸å¤šæ¨¡æ€æ¨¡å‹çš„è¯„ä¼°éœ€æ±‚ï¼Œæ—¨åœ¨ç³»ç»Ÿæ€§åœ°è¡¡é‡å¤§æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œå¹¶æ¨åŠ¨å…¶æŒç»­æ¼”è¿›ä¸ä¼˜åŒ–ã€‚

ç›®å‰ï¼Œè¯¥é¡¹ç›®ä¸­æ‰€æœ‰ä½¿ç”¨çš„æ•°æ®å·²ç»åœ¨huggingface ä¸Šå¼€æºï¼Œåœ°å€ä¸ºï¼š

https://huggingface.co/datasets/R-Bench/R-Bench

å…³äºé¡¹ç›®çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·è®¿é—®é¡¹ç›®å®˜ç½‘ï¼š

https://evalmodels.github.io/rbench/

è®ºæ–‡é“¾æ¥ï¼š

https://arxiv.org/pdf/2505.02018

5. OlympicArena

ä¸Šæµ·äº¤é€šå¤§å­¦ç”Ÿæˆå¼äººå·¥æ™ºèƒ½å®éªŒå®¤ (GAIR Lab) çš„ç ”ç©¶å›¢é˜Ÿæ¨å‡ºå¤šå­¦ç§‘è®¤çŸ¥æ¨ç†åŸºå‡†OlympicArenaï¼Œå³ä½¿æ˜¯GPT-4o ä¹Ÿåªè¾¾åˆ°äº† 34.01% çš„æ•´ä½“å‡†ç¡®ç‡ï¼Œè€Œå…¶ä»–å¼€æºæ¨¡å‹çš„æ•´ä½“å‡†ç¡®ç‡ä¹Ÿéš¾ä»¥è¾¾åˆ°20%ã€‚

è®ºæ–‡åœ°å€ï¼š https://arxiv.org/pdf/2406.12753

é¡¹ç›®åœ°å€ï¼š https://gair-nlp.github.io/OlympicArena/

ä»£ç åœ°å€ï¼š https://github.com/GAIR-NLP/OlympicArena

æ•°æ®åœ°å€ï¼šhttps://huggingface.co/datasets/GAIR/OlympicArena

6. 
æ¥è‡ªç ”ç©¶å›¢é˜Ÿçš„ä¸€é¡¹æœ€æ–°ç ”ç©¶å¼•å…¥äº†ä¸€ä¸ªå…¨æ–°çš„TEXTGAMESåŸºå‡†ï¼Œè¯¥åŸºå‡†é€šè¿‡æ–‡æœ¬æ¨ç†æ¸¸æˆæ¥ç³»ç»Ÿè¯„ä¼°LLMsçš„é€»è¾‘æ¨ç†èƒ½åŠ›ã€‚ç ”ç©¶å‘ç°ï¼Œå³ä¾¿æ˜¯æœ€å…ˆè¿›çš„å¤§æ¨¡å‹ï¼Œåœ¨æŸäº›å¤æ‚ä»»åŠ¡ä¸Šä¾ç„¶å­˜åœ¨æ˜¾è‘—çŸ­æ¿ï¼Œå°¤å…¶æ˜¯åœ¨åºåˆ—æ¨ç†ã€è®¡æ•°ã€å¤æ‚è§„åˆ™éµå¾ªç­‰æ–¹é¢è¡¨ç°ä¸ä½³ã€‚

è®ºæ–‡æ ‡é¢˜ï¼šTextGames: Learning to Self-Play Text-Based Puzzle Games via Language Model Reasoning

è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2502.18431    

https://github.com/fhudi/textgames

7. Operations Research Question Answeringï¼ˆORQAï¼‰

æ•°æ®é›†(https://arxiv.org/pdf/2412.17874ï¼Œæµ‹è¯•æ•°æ®åœ°å€ï¼šhttps://github.com/nl4opt/ORQA)ï¼Œ

ç”¨äºè¯„ä¼°LLMsåœ¨è¿ç­¹å­¦é¢†åŸŸçš„æ³›åŒ–èƒ½åŠ›ï¼Œé‡ç‚¹åœ¨äºå¯¹ORé—®é¢˜çš„â€œç†è§£â€ä¸Šã€‚


8. é˜¿é‡Œ DAIL-SQLï¼š

å¤§å‹è¯­è¨€æ¨¡å‹æ”¯æŒçš„æ–‡æœ¬åˆ° SQLï¼šåŸºå‡†è¯„ä¼°

è®ºæ–‡åœ°å€ï¼šhttps://arxiv.org/pdf/2308.15363

Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation

ä»£ç åœ°å€ï¼šhttps://github.com/BeachWang/DAIL-SQL

åŸæ–‡é“¾æ¥ï¼šhttps://www.yuque.com/u21774036/qnmlr1/ilxxsoh26grbafe4
---

Code:

1. LiveCodeBench Pro

æ¥è‡ªçº½çº¦å¤§å­¦ã€æ™®æ—æ–¯é¡¿å¤§å­¦ç­‰ 8 å®¶æœºæ„çš„ç ”ç©¶è€…æå‡ºäº†Â LiveCodeBench Proï¼Œè¿™æ˜¯ä¸€ä¸ªæå…·æŒ‘æˆ˜æ€§çš„ç«æŠ€ç¼–ç¨‹åŸºå‡†æµ‹è¯•ã€‚
å€¼å¾—ä¸€æçš„æ˜¯ï¼Œè¿™é¡¹ç ”ç©¶æœ‰å¤šä½å‚åŠ è¿‡å›½é™…ç®—æ³•ç«èµ›ã€‚ä¾‹å¦‚ï¼Œä½œè€…ä¹‹ä¸€ã€çº½çº¦å¤§å­¦æœ¬ç§‘ç”Ÿ Zihan Zheng æ›¾ä»£è¡¨å­¦æ ¡å‚åŠ  ICPC ä¸–ç•Œæ€»å†³èµ›ã€‚
LiveCodeBench Pro æ”¶å½•äº† 584 é“æˆªè‡³ 2025 å¹´ 4 æœˆ 25 æ—¥çš„é«˜è´¨é‡é¢˜ç›®ï¼Œè¿™äº›é¢˜ç›®å‡æ¥è‡ª Codeforces ã€ICPC ç³»åˆ—èµ›å’Œ IOI ç³»åˆ—èµ›ç­‰é¡¶çº§èµ›äº‹ã€‚å¹¶ä¸”è¿™äº›é—®é¢˜ä¼šä¸æ–­æ›´æ–°ä»¥é™ä½å¯èƒ½çš„æ•°æ®æ±¡æŸ“ã€‚
è®ºæ–‡æ ‡é¢˜ï¼šLiveCodeBench Pro: How Do Olympiad Medalists Judge LLMs in Competitive Programming?Â 
è®ºæ–‡åœ°å€ï¼šhttps://arxiv.org/pdf/2506.11928
é¡¹ç›®ä¸»é¡µï¼šhttps://livecodebenchpro.com/GitHub
https://github.com/GavinZhengOI/LiveCodeBench-Pro

2. Aider LLM Leaderboards çš„æ ¸å¿ƒç‰¹ç‚¹ã€‘

æ³¨é‡çœŸå®ä¸–ç•Œçš„å·¥ä½œæµ (Real-world Workflow)ä¸ HumanEval ç­‰è¯„æµ‹åŸºå‡†ä¸åŒï¼ˆé‚£äº›é€šå¸¸åªæµ‹è¯•æ¨¡å‹èƒ½å¦ä¸€æ¬¡æ€§ç”Ÿæˆæ­£ç¡®çš„å‡½æ•°ä»£ç ï¼‰ï¼ŒAider æ’è¡Œæ¦œæ¨¡æ‹Ÿçš„æ˜¯ä¸€ä¸ªæ›´çœŸå®çš„å¼€å‘æµç¨‹ã€‚
å®ƒæµ‹è¯•çš„æ˜¯æ¨¡å‹ç¼–è¾‘ç°æœ‰ä»£ç ã€ä¿®å¤ Bug å’Œæ ¹æ®éœ€æ±‚æ·»åŠ æ–°åŠŸèƒ½çš„èƒ½åŠ›ï¼Œè¿™é€šå¸¸æ¶‰åŠå¤šä¸ªæ–‡ä»¶çš„ä¿®æ”¹å’Œåå¤è°ƒè¯•

è¯„æµ‹çš„æ˜¯â€œç³»ç»Ÿâ€è€Œéâ€œçº¯æ¨¡å‹â€

è¿™ä¸ªæ’è¡Œæ¦œè¡¡é‡çš„ä¸ä»…ä»…æ˜¯ LLM æœ¬èº«ï¼Œè€Œæ˜¯ Aider + LLM è¿™ä¸ªç»„åˆç³»ç»Ÿçš„æ•´ä½“è¡¨ç°ã€‚
Aider çš„æç¤ºå·¥ç¨‹ï¼ˆPrompt Engineeringï¼‰ã€ä¸Šä¸‹æ–‡ç®¡ç†èƒ½åŠ›ä»¥åŠä¸æ¨¡å‹çš„äº¤äº’æ–¹å¼ï¼Œéƒ½ä¼šç›´æ¥å½±å“æœ€ç»ˆç»“æœã€‚å› æ­¤ï¼Œå®ƒè¡¡é‡çš„æ˜¯æ¨¡å‹åœ¨ç‰¹å®šå·¥å…·è¾…åŠ©ä¸‹çš„å®ç”¨æ•ˆèƒ½

åŸºäºå®é™…ç¼–ç¨‹æŒ‘æˆ˜

Aider æ’è¡Œæ¦œä½¿ç”¨äº†æ¥è‡ª Exercism å¹³å°çš„ç¼–ç¨‹ç»ƒä¹ ä½œä¸ºè¯„æµ‹åŸºå‡†ã€‚è¿™äº›ç»ƒä¹ é€šå¸¸åŒ…å«ä¸€ä¸ªé—®é¢˜æè¿°æ–‡ä»¶ï¼ˆREADME.mdï¼‰ã€ä¸€äº›èµ·å§‹ä»£ç å’Œä¸€å¥—å•å…ƒæµ‹è¯•
æ¨¡å‹çš„ä»»åŠ¡å°±æ˜¯ç†è§£éœ€æ±‚ï¼Œç„¶åä¿®æ”¹ä»£ç ï¼Œç›´åˆ°æ‰€æœ‰çš„å•å…ƒæµ‹è¯•éƒ½èƒ½æˆåŠŸé€šè¿‡

The polyglot benchmark
Like aiderâ€™s original code editing benchmark, the new polyglot benchmark is based on Exercism coding exercises.

The new polyglot benchmark:

Contains coding problems in C++, Go, Java, JavaScript, Python and Rust. The old benchmark was solely based on Python exercises.
Focuses on the most difficult 225 exercises out of the 697 that Exercism provides for those languages. The old benchmark simply included all 133 Python exercises, regardless of difficulty.

https://github.com/Aider-AI/polyglot-benchmark

3. 

Agenticï¼š
1. Scientistsâ€™ First Exam

ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤ AI4S å›¢é˜Ÿæ¨å‡ºäº†Â Scientistsâ€™ First Examï¼ˆä»¥ä¸‹ç®€ç§° SFEï¼‰â€”â€” ç³»ç»Ÿè¯„ä¼°å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆMLLMsï¼‰å¤šå­¦ç§‘ã€é«˜éš¾åº¦çš„ç§‘å­¦ä¸“ä¸šé¢†åŸŸè®¤çŸ¥èƒ½åŠ›çš„è¯„æµ‹åŸºå‡†ã€‚
SFE 
æŠ€æœ¯æŠ¥å‘Šé“¾æ¥: https://arxiv.org/abs/2506.10521SFE 
æ•°æ®é›†é“¾æ¥ï¼šhttps://huggingface.co/datasets/PrismaX/SFESFE 
è¯„æµ‹åŸºå‡†å·²ä¸Šæ¶åˆ°å¸å—è¯„æµ‹é›†ç¤¾åŒºï¼Œæ¬¢è¿è®¿é—®ï¼šhttps://hub.opencompass.org.cn/dataset-detail/SFE

https://huggingface.co/datasets/PrismaX/SFE/tree/main

2. browsecomp
 https://openai.com/index/browsecomp/

3. é¦–ä¸ªGUIå¤šæ¨¡æ€å¤§æ¨¡å‹æ™ºèƒ½ä½“å¯ä¿¡è¯„æµ‹æ¡†æ¶+åŸºå‡†ï¼šMLA-Trust
ğŸ“„ è®ºæ–‡ï¼šhttps://arxiv.org/pdf/2506.01616

ğŸŒ é¡¹ç›®ä¸»é¡µï¼šhttps://mla-trust.github.io

ğŸ’» ä»£ç ä»“åº“ï¼šhttps://github.com/thu-ml/MLA-Trust

4. CRMArena-Pro
CRMArena-Pro: Holistic Assessment of LLM Agents Across Diverse Business Scenarios and Interactions

https://huggingface.co/datasets/Salesforce/CRMArenaPro

https://github.com/SalesforceAIResearch/CRMArena

GC:
1. XVerseBenchåŸºå‡†æµ‹è¯•
ä¸ºäº†å…¨é¢è¯„ä¼°å¤šä¸»ä½“æ§åˆ¶å›¾åƒç”Ÿæˆèƒ½åŠ›ï¼Œå­—èŠ‚æå‡ºäº†XVerseBenchåŸºå‡†æµ‹è¯•ã€‚è¯¥æµ‹è¯•çš„æ•°æ®é›†ä¸»é¢˜ä¸°å¯Œå¤šæ ·ï¼ŒåŒ…å«20ç§ä¸åŒçš„äººç±»èº«ä»½ã€74ç§ç‹¬ç‰¹çš„ç‰©å“ï¼Œä»¥åŠ45ç§ä¸åŒçš„åŠ¨ç‰©ç‰©ç§æˆ–ä¸ªä½“ï¼Œå…±è®¾æœ‰300ä¸ªç‹¬ç‰¹çš„æµ‹è¯•æç¤ºã€‚ä¸ä»…å¦‚æ­¤ï¼ŒXVerseBenchè¿˜é‡‡ç”¨å¤šç»´è¯„ä¼°æŒ‡æ ‡ï¼šDPGè¯„åˆ†ï¼šè¯„ä¼°æ¨¡å‹çš„ç¼–è¾‘åŠŸèƒ½ï¼›Face IDç›¸ä¼¼åº¦ï¼šè¯„ä¼°æ¨¡å‹ç»´æŠ¤äººç±»èº«ä»½çš„èƒ½åŠ›ï¼›DINOv2ç›¸ä¼¼åº¦ï¼šè¯„ä¼°æ¨¡å‹ä¿æŒå¯¹è±¡ç‰¹å¾çš„èƒ½åŠ›ï¼›ç¾å­¦è¯„åˆ†ï¼šè¯„ä¼°ç”Ÿæˆå›¾åƒçš„ç¾å­¦è´¨é‡ã€‚
è®ºæ–‡åœ°å€ï¼šhttps://arxiv.org/abs/2506.21416
å‚è€ƒé“¾æ¥ï¼šhttps://bytedance.github.io/XVerse/



https://www.codabench.org/

https://opencompass.org.cn/large-model
