# GoodBench
collection of some good benchmarks

Vision Language:
1. Saliency-Bench: A Comprehensive Benchmark for Evaluating Visual Explanations
论文链接: https://arxiv.org/abs/2310.08537
项目主页: 
https://github.com/yifeizhangcs/XAIdataset.github.io
特点：
*全面的数据集集合：精心构建并标注了8个数据集，覆盖了从性别分类、环境识别到癌症诊断和行为分类等多种任务，并且包含了二分类和多分类问题。
*标准化的评估流程：开发了一套统一的评估流水线，能够对不同显著性方法生成的视觉解释进行标准化处理，并使用统一的指标进行衡量，确保了实验的可复现性。
*广泛的基准测试和分析：对6种主流的显著性方法（如GradCAM, RISE等）在不同模型架构（ResNet-18, VGG-19, ViT）上进行了大规模的基准测试，并提供了深入的性能分析。
*用户友好的评估工具包：提供了一个易于使用的Python工具包，封装了数据加载、模型评估等功能，极大地简化了研究人员的评估过程。

Language:

多任务基准：
论文标题：REST: Stress Testing Large Reasoning Models by Asking Multiple Problems at Once 
论文链接：https://arxiv.org/abs/2507.10541


Code:

